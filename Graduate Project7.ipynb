{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import Series, DataFrame\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=0, n_jobs = -1)\n",
    "logreg = LogisticRegression(solver='liblinear',multi_class='ovr')\n",
    "svm = SVC(gamma='auto')\n",
    "xgb = xgb.XGBClassifier()\n",
    "gnb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MUSK</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>159</th>\n",
       "      <th>160</th>\n",
       "      <th>161</th>\n",
       "      <th>162</th>\n",
       "      <th>163</th>\n",
       "      <th>164</th>\n",
       "      <th>165</th>\n",
       "      <th>166</th>\n",
       "      <th>167</th>\n",
       "      <th>168</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MUSK</td>\n",
       "      <td>46</td>\n",
       "      <td>-108</td>\n",
       "      <td>-60</td>\n",
       "      <td>-69</td>\n",
       "      <td>-117</td>\n",
       "      <td>49</td>\n",
       "      <td>38</td>\n",
       "      <td>-161</td>\n",
       "      <td>-8</td>\n",
       "      <td>...</td>\n",
       "      <td>-308</td>\n",
       "      <td>52</td>\n",
       "      <td>-7</td>\n",
       "      <td>39</td>\n",
       "      <td>126</td>\n",
       "      <td>156</td>\n",
       "      <td>-50</td>\n",
       "      <td>-112</td>\n",
       "      <td>96</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MUSK</td>\n",
       "      <td>41</td>\n",
       "      <td>-188</td>\n",
       "      <td>-145</td>\n",
       "      <td>22</td>\n",
       "      <td>-117</td>\n",
       "      <td>-6</td>\n",
       "      <td>57</td>\n",
       "      <td>-171</td>\n",
       "      <td>-39</td>\n",
       "      <td>...</td>\n",
       "      <td>-59</td>\n",
       "      <td>-2</td>\n",
       "      <td>52</td>\n",
       "      <td>103</td>\n",
       "      <td>136</td>\n",
       "      <td>169</td>\n",
       "      <td>-61</td>\n",
       "      <td>-136</td>\n",
       "      <td>79</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MUSK</td>\n",
       "      <td>46</td>\n",
       "      <td>-194</td>\n",
       "      <td>-145</td>\n",
       "      <td>28</td>\n",
       "      <td>-117</td>\n",
       "      <td>73</td>\n",
       "      <td>57</td>\n",
       "      <td>-168</td>\n",
       "      <td>-39</td>\n",
       "      <td>...</td>\n",
       "      <td>-134</td>\n",
       "      <td>-154</td>\n",
       "      <td>57</td>\n",
       "      <td>143</td>\n",
       "      <td>142</td>\n",
       "      <td>165</td>\n",
       "      <td>-67</td>\n",
       "      <td>-145</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MUSK</td>\n",
       "      <td>41</td>\n",
       "      <td>-188</td>\n",
       "      <td>-145</td>\n",
       "      <td>22</td>\n",
       "      <td>-117</td>\n",
       "      <td>-7</td>\n",
       "      <td>57</td>\n",
       "      <td>-170</td>\n",
       "      <td>-39</td>\n",
       "      <td>...</td>\n",
       "      <td>-60</td>\n",
       "      <td>-4</td>\n",
       "      <td>52</td>\n",
       "      <td>104</td>\n",
       "      <td>136</td>\n",
       "      <td>168</td>\n",
       "      <td>-60</td>\n",
       "      <td>-135</td>\n",
       "      <td>80</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MUSK</td>\n",
       "      <td>41</td>\n",
       "      <td>-188</td>\n",
       "      <td>-145</td>\n",
       "      <td>22</td>\n",
       "      <td>-117</td>\n",
       "      <td>-7</td>\n",
       "      <td>57</td>\n",
       "      <td>-170</td>\n",
       "      <td>-39</td>\n",
       "      <td>...</td>\n",
       "      <td>-60</td>\n",
       "      <td>-4</td>\n",
       "      <td>52</td>\n",
       "      <td>104</td>\n",
       "      <td>137</td>\n",
       "      <td>168</td>\n",
       "      <td>-60</td>\n",
       "      <td>-135</td>\n",
       "      <td>80</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 168 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MUSK   2    3    4   5    6   7   8    9  10  ...  159  160  161  162  163  \\\n",
       "0  MUSK  46 -108  -60 -69 -117  49  38 -161  -8  ... -308   52   -7   39  126   \n",
       "1  MUSK  41 -188 -145  22 -117  -6  57 -171 -39  ...  -59   -2   52  103  136   \n",
       "2  MUSK  46 -194 -145  28 -117  73  57 -168 -39  ... -134 -154   57  143  142   \n",
       "3  MUSK  41 -188 -145  22 -117  -7  57 -170 -39  ...  -60   -4   52  104  136   \n",
       "4  MUSK  41 -188 -145  22 -117  -7  57 -170 -39  ...  -60   -4   52  104  137   \n",
       "\n",
       "   164  165  166  167  168  \n",
       "0  156  -50 -112   96  1.0  \n",
       "1  169  -61 -136   79  1.0  \n",
       "2  165  -67 -145   39  1.0  \n",
       "3  168  -60 -135   80  1.0  \n",
       "4  168  -60 -135   80  1.0  \n",
       "\n",
       "[5 rows x 168 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database1 = pd.read_csv(\"data.csv\", sep=';')\n",
    "database1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = database1.drop([\"MUSK\",\"168\"],axis=1)\n",
    "y = database1['168']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.10 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(name):\n",
    "    name.fit(X_train, y_train)\n",
    "    y_pred = name.predict(X_test)\n",
    "    score= accuracy_score(y_test, y_pred) * 100\n",
    "    print(str(name) + \"Accuracy:\",score)\n",
    "    report_name=classification_report(y_test, y_pred)\n",
    "    print(report_name)\n",
    "    print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfe(model):  \n",
    "    rfe = RFE(model, 16)\n",
    "    fit = rfe.fit(X, y)\n",
    "    print(\"Num Features: %s\" % (fit.n_features_))\n",
    "    print(\"Selected Features: %s\" % (fit.support_))\n",
    "    print(\"Feature Ranking: %s\" % (fit.ranking_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossval(model):\n",
    "    scores=cross_val_score(model, X, y, cv=10, scoring =\"accuracy\")\n",
    "    print(str(model) + \"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')Accuracy: 96.36363636363636\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.97      0.98       557\n",
      "         1.0       0.87      0.90      0.89       103\n",
      "\n",
      "    accuracy                           0.96       660\n",
      "   macro avg       0.93      0.94      0.93       660\n",
      "weighted avg       0.96      0.96      0.96       660\n",
      "\n",
      "[[543  14]\n",
      " [ 10  93]]\n",
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')Accuracy: 0.78 (+/- 0.39)\n",
      "Num Features: 16\n",
      "Selected Features: [False False False False False False False False  True False False False\n",
      " False False False False  True False False False False False False False\n",
      " False False False False False False False  True False False False  True\n",
      " False  True False False False False False False False False False False\n",
      " False  True False False False  True False False False False False False\n",
      " False False False False False  True False False False False False False\n",
      " False False False False  True False False False False False  True False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False  True False  True False  True False False False False False  True\n",
      " False False False False False False False  True False False False False\n",
      " False False False False False False  True False False False False False\n",
      " False False False False False False False False False False]\n",
      "Feature Ranking: [147 146  45  44  52  33  66  39   1  63  58  68  71  55  80  64   1  65\n",
      "  91  16  56   6  82  99  25 105  13  60  43  93  72   1 112  29  11   1\n",
      "  97   1  28  78 135  26  10  86  83  94  92  37 109   1 134  14 108   1\n",
      "   7  35 149 118 117 126 130 129  20  24 100   1 111  48  36 131 122 137\n",
      " 142 138  18 140   1 113 151 103  70 119   1 150   9 128  90  59   4  81\n",
      "  73  40  12  67  69  17  62  85   5  75  30  88  21   8 124   3  84  34\n",
      "  96  95  50 136 116  89 102  32  22 121  74  57  31   1 110   1 115   1\n",
      " 125 132 127  49  47   1  15  76 101  42  79 104 114   1  38  46  41 120\n",
      " 141  98 123 133 143 139   1  23  53  87 107  27  61 106  77  54  51  19\n",
      "   2 144 145 148]\n"
     ]
    }
   ],
   "source": [
    "model(dt)\n",
    "crossval(dt)\n",
    "rfe(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=-1, oob_score=False, random_state=0, verbose=0,\n",
      "                       warm_start=False)Accuracy: 98.48484848484848\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99       557\n",
      "         1.0       0.99      0.91      0.95       103\n",
      "\n",
      "    accuracy                           0.98       660\n",
      "   macro avg       0.99      0.96      0.97       660\n",
      "weighted avg       0.98      0.98      0.98       660\n",
      "\n",
      "[[556   1]\n",
      " [  9  94]]\n",
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=-1, oob_score=False, random_state=0, verbose=0,\n",
      "                       warm_start=False)Accuracy: 0.80 (+/- 0.41)\n",
      "Num Features: 16\n",
      "Selected Features: [False False False False False False False False  True False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False  True\n",
      " False False False False False False False False False False False False\n",
      " False  True False  True False False False False False False False False\n",
      " False False False False False  True False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False  True False False  True False\n",
      " False False False False False False False False False False False False\n",
      " False  True False False False False False False False False False False\n",
      " False  True False  True False  True False False False False False  True\n",
      " False False False False False False False  True False False False False\n",
      " False False False False False False  True False False False False False\n",
      " False False False False False  True  True False False False]\n",
      "Feature Ranking: [  7 143  50  72 150  77  87  83   1  20 110 136  45  19 128 145  28 123\n",
      "  38  44   2   8  58 121  17  95 131 134  94  96 106  25  43  53  24   1\n",
      " 140  40  74 130  76  29   5  69   4 125 144  68  86   1  49   1  56  98\n",
      "  32  59 147  90  42 105  10  97   9  92 116   1 151  47 138 113 108  31\n",
      " 122 126  62 149  91  82  23  39  89  22  12  75  11  16 139 119  26 114\n",
      " 127   1  61  81   1  27 120  60  71 141 115  13  55  63  35  93  73  46\n",
      "  15   1  66  30 102  99  37  36  65  54 135 112  84   1  52   1  41   1\n",
      " 103  57  78  64  51   1  18  80  67 129 137 101 104   1  21 132  70  33\n",
      " 142  88 148 118 117  79   1 124  85 100 107 111 146 109 133   3  48   1\n",
      "   1  34   6  14]\n"
     ]
    }
   ],
   "source": [
    "model(rf)\n",
    "crossval(rf)\n",
    "rfe(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='ovr', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)Accuracy: 95.3030303030303\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.97      0.97       557\n",
      "         1.0       0.86      0.83      0.85       103\n",
      "\n",
      "    accuracy                           0.95       660\n",
      "   macro avg       0.91      0.90      0.91       660\n",
      "weighted avg       0.95      0.95      0.95       660\n",
      "\n",
      "[[543  14]\n",
      " [ 17  86]]\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='ovr', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)Accuracy: 0.81 (+/- 0.28)\n",
      "Num Features: 16\n",
      "Selected Features: [False False False False False False False False False False False False\n",
      "  True False False False False False False False False False False False\n",
      " False False  True False False False False False False False False False\n",
      " False False False False  True False  True False False False False False\n",
      " False False False False False False False False  True  True False False\n",
      " False False False False False False  True False False False False  True\n",
      " False False False False False False False False False False False False\n",
      " False False  True False False False False False False False False False\n",
      " False False  True False False False False False False False False False\n",
      " False False False False False False False False False False  True False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False  True False False False False False False\n",
      " False False False False  True False False False False False False False\n",
      " False False False  True False  True  True False False False]\n",
      "Feature Ranking: [ 16  48  14  73 144  60 145  95  13  10  71  35   1  62  63  65   4 122\n",
      " 142 140 135  12 127 138  67  88   1 101  55 125  49  43  17 130  25  39\n",
      "  99  19  38  31   1  41   1 146  85 147  46  78  94  21  80   6  76 150\n",
      " 148  91   1   1  57 106 117 123 114 108  27  18   1 102 141  32  15   1\n",
      "  70  84  87  82 124  64  93 139  75 121  81 116   9  45   1  92  97  59\n",
      " 134  51  54  69 149   2 133   5   1 103  40  52  74  86  61 129  83 104\n",
      " 111 112 110 128  77  29 105 107  72  90   1  11  66  56  58  98   3  50\n",
      "   8 126   7  26  28 119  79  36  96  20  47   1  33  34 109 151  68  23\n",
      " 143 120  37 118   1  30  24  53 137 100  42  44 136 113 131   1 132   1\n",
      "   1  22  89 115]\n"
     ]
    }
   ],
   "source": [
    "model(logreg)\n",
    "crossval(logreg)\n",
    "rfe(logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)Accuracy: 90.9090909090909\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      1.00      0.95       557\n",
      "         1.0       1.00      0.42      0.59       103\n",
      "\n",
      "    accuracy                           0.91       660\n",
      "   macro avg       0.95      0.71      0.77       660\n",
      "weighted avg       0.92      0.91      0.89       660\n",
      "\n",
      "[[557   0]\n",
      " [ 60  43]]\n",
      "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)Accuracy: 0.85 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "model(svm)\n",
    "crossval(svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
      "              nthread=None, objective='binary:logistic', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=None, subsample=1, verbosity=1)Accuracy: 97.12121212121212\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.98       557\n",
      "         1.0       0.95      0.86      0.90       103\n",
      "\n",
      "    accuracy                           0.97       660\n",
      "   macro avg       0.96      0.93      0.94       660\n",
      "weighted avg       0.97      0.97      0.97       660\n",
      "\n",
      "[[552   5]\n",
      " [ 14  89]]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
      "              nthread=None, objective='binary:logistic', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=None, subsample=1, verbosity=1)Accuracy: 0.82 (+/- 0.31)\n",
      "Num Features: 16\n",
      "Selected Features: [ True False False False False False False False  True False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False  True False  True False  True  True\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False  True False False\n",
      " False False  True False False  True False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False  True False  True False  True False False False False False  True\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False  True False False False False False\n",
      " False False False False False False  True False  True False]\n",
      "Feature Ranking: [  1  78  63   5  86  75  69  93   1  54 126 128  39  10  45 134  28 116\n",
      " 120  82   3  55 112  94  67   8 127  95 104  66   1  60   1  64   1   1\n",
      "  88 131 118 110 113  68  27  11 135 137  72 149 151  40  73 106  74  85\n",
      "   4 107  84   1  29 132  12  91   1  30  58   1  22  26 102  81  56  17\n",
      " 115  89  92  90  59  53  44  50 143 145  21  80  79  71 121  18 101 100\n",
      "  24  13  83 103  76  43 142 148 122 124  37   6 130  35  20  51 144 138\n",
      "  36  15  19 141 140 139  61  34  57 150  62  99 108   1 129   1 117   1\n",
      "  46 146  16  41 105   1  38  96  70  32 123  87 119  14  65  25  52   9\n",
      "  23  33 114   7 125 133   1 147  48  31 111  47 136  77 109  49  97   2\n",
      "   1  42   1  98]\n"
     ]
    }
   ],
   "source": [
    "model(xgb)\n",
    "crossval(xgb)\n",
    "rfe(xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(priors=None, var_smoothing=1e-09)Accuracy: 84.84848484848484\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.86      0.91       557\n",
      "         1.0       0.51      0.79      0.62       103\n",
      "\n",
      "    accuracy                           0.85       660\n",
      "   macro avg       0.73      0.82      0.76       660\n",
      "weighted avg       0.89      0.85      0.86       660\n",
      "\n",
      "[[479  78]\n",
      " [ 22  81]]\n",
      "GaussianNB(priors=None, var_smoothing=1e-09)Accuracy: 0.80 (+/- 0.31)\n"
     ]
    }
   ],
   "source": [
    "model(gnb)\n",
    "crossval(gnb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>21</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>48</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>36</td>\n",
       "      <td>92</td>\n",
       "      <td>56</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>-5</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>18</td>\n",
       "      <td>40</td>\n",
       "      <td>48</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>-26</td>\n",
       "      <td>43</td>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f1  f2  f3  f4  f5  f6  f7  f8  f9  d\n",
       "0  50  21  77   0  28   0  27  48  22  2\n",
       "1  55   0  92   0   0  26  36  92  56  4\n",
       "2  53   0  82   0  52  -5  29  30   2  1\n",
       "3  37   0  76   0  28  18  40  48   8  1\n",
       "4  37   0  79   0  34 -26  43  46   2  1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database2 = pd.read_csv(\"shuttle-train.csv\", sep=';')\n",
    "database2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>-6</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>88</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>-4</td>\n",
       "      <td>40</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>-1</td>\n",
       "      <td>89</td>\n",
       "      <td>-7</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>9</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>-2</td>\n",
       "      <td>25</td>\n",
       "      <td>37</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>-6</td>\n",
       "      <td>26</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f1  f2  f3  f4  f5  f6  f7  f8  f9  d\n",
       "0  55   0  81   0  -6  11  25  88  64  4\n",
       "1  56   0  96   0  52  -4  40  44   4  4\n",
       "2  50  -1  89  -7  50   0  39  40   2  1\n",
       "3  53   9  79   0  42  -2  25  37  12  4\n",
       "4  55   2  82   0  54  -6  26  28   2  1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database3 = pd.read_csv(\"shuttle-test.csv\", sep=';')\n",
    "database3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train = database2.drop([\"d\"], axis=1)\n",
    "X1_test = database3.drop([\"d\"], axis=1)\n",
    "y1_train = database2['d']\n",
    "y1_test = database3['d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model1(name):\n",
    "    name.fit(X1_train, y1_train)\n",
    "    y1_pred = name.predict(X1_test)\n",
    "    score= accuracy_score(y1_test, y1_pred) * 100\n",
    "    print(str(name) + \"Accuracy:\",score)\n",
    "    report_name=classification_report(y1_test, y1_pred)\n",
    "    print(report_name)\n",
    "    print(confusion_matrix(y1_test,y1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfe1(model):    \n",
    "    rfe = RFE(model, 3)\n",
    "    fit = rfe.fit(df_row_reindex_X, df_row_reindex_y)\n",
    "    print(\"Num Features: %s\" % (fit.n_features_))\n",
    "    print(\"Selected Features: %s\" % (fit.support_))\n",
    "    print(\"Feature Ranking: %s\" % (fit.ranking_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_row_reindex = pd.concat([database2, database3], ignore_index=True)\n",
    "df_row_reindex_X = df_row_reindex.drop([\"d\"], axis=1)\n",
    "df_row_reindex_y = df_row_reindex['d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossval(model):\n",
    "    scores=cross_val_score(model, df_row_reindex_X, df_row_reindex_y, cv=10, scoring =\"accuracy\")\n",
    "    print(str(model) + \"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1(SVC(gamma='auto'))\n",
    "crossval(SVC(gamma='auto'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')Accuracy: 99.98620689655172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00     11478\n",
      "           2       1.00      0.92      0.96        13\n",
      "           3       1.00      1.00      1.00        39\n",
      "           4       1.00      1.00      1.00      2155\n",
      "           5       1.00      1.00      1.00       809\n",
      "           6       1.00      1.00      1.00         4\n",
      "           7       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00     14500\n",
      "   macro avg       1.00      0.99      0.99     14500\n",
      "weighted avg       1.00      1.00      1.00     14500\n",
      "\n",
      "[[11478     0     0     0     0     0     0]\n",
      " [    0    12     0     1     0     0     0]\n",
      " [    0     0    39     0     0     0     0]\n",
      " [    0     0     0  2155     0     0     0]\n",
      " [    1     0     0     0   808     0     0]\n",
      " [    0     0     0     0     0     4     0]\n",
      " [    0     0     0     0     0     0     2]]\n",
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')Accuracy: 1.00 (+/- 0.00)\n",
      "Num Features: 3\n",
      "Selected Features: [ True False False False False False  True False  True]\n",
      "Feature Ranking: [1 2 7 6 4 5 1 3 1]\n"
     ]
    }
   ],
   "source": [
    "model1(dt)\n",
    "crossval(dt)\n",
    "rfe1(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=-1, oob_score=False, random_state=0, verbose=0,\n",
      "                       warm_start=False)Accuracy: 99.97931034482758\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00     11478\n",
      "           2       1.00      0.92      0.96        13\n",
      "           3       0.97      1.00      0.99        39\n",
      "           4       1.00      1.00      1.00      2155\n",
      "           5       1.00      1.00      1.00       809\n",
      "           6       1.00      0.75      0.86         4\n",
      "           7       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           1.00     14500\n",
      "   macro avg       1.00      0.88      0.92     14500\n",
      "weighted avg       1.00      1.00      1.00     14500\n",
      "\n",
      "[[11478     0     0     0     0     0     0]\n",
      " [    0    12     0     1     0     0     0]\n",
      " [    0     0    39     0     0     0     0]\n",
      " [    0     0     0  2155     0     0     0]\n",
      " [    0     0     0     0   809     0     0]\n",
      " [    0     0     0     1     0     3     0]\n",
      " [    0     0     1     0     0     0     1]]\n",
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=-1, oob_score=False, random_state=0, verbose=0,\n",
      "                       warm_start=False)Accuracy: 1.00 (+/- 0.00)\n",
      "Num Features: 3\n",
      "Selected Features: [ True False False False False False  True False  True]\n",
      "Feature Ranking: [1 5 4 7 2 6 1 3 1]\n"
     ]
    }
   ],
   "source": [
    "model1(rf)\n",
    "crossval(rf)\n",
    "rfe1(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='ovr', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)Accuracy: 93.10344827586206\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.93      0.99      0.96     11478\n",
      "           2       0.00      0.00      0.00        13\n",
      "           3       0.00      0.00      0.00        39\n",
      "           4       0.91      0.61      0.73      2155\n",
      "           5       1.00      1.00      1.00       809\n",
      "           6       0.00      0.00      0.00         4\n",
      "           7       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.93     14500\n",
      "   macro avg       0.41      0.37      0.38     14500\n",
      "weighted avg       0.93      0.93      0.92     14500\n",
      "\n",
      "[[11372     0     0   104     0     0     2]\n",
      " [    8     0     0     5     0     0     0]\n",
      " [   17     0     0    22     0     0     0]\n",
      " [  835     0     0  1320     0     0     0]\n",
      " [    1     0     0     0   808     0     0]\n",
      " [    0     0     0     4     0     0     0]\n",
      " [    2     0     0     0     0     0     0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmet\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='ovr', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)Accuracy: 0.93 (+/- 0.01)\n",
      "Num Features: 3\n",
      "Selected Features: [False False False False  True False  True  True False]\n",
      "Feature Ranking: [4 5 2 6 1 7 1 1 3]\n"
     ]
    }
   ],
   "source": [
    "model1(logreg)\n",
    "crossval(logreg)\n",
    "rfe1(logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
      "              nthread=None, objective='multi:softprob', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=None, subsample=1, verbosity=1)Accuracy: 99.99310344827586\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00     11478\n",
      "           2       1.00      0.92      0.96        13\n",
      "           3       1.00      1.00      1.00        39\n",
      "           4       1.00      1.00      1.00      2155\n",
      "           5       1.00      1.00      1.00       809\n",
      "           6       1.00      1.00      1.00         4\n",
      "           7       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00     14500\n",
      "   macro avg       1.00      0.99      0.99     14500\n",
      "weighted avg       1.00      1.00      1.00     14500\n",
      "\n",
      "[[11478     0     0     0     0     0     0]\n",
      " [    0    12     0     1     0     0     0]\n",
      " [    0     0    39     0     0     0     0]\n",
      " [    0     0     0  2155     0     0     0]\n",
      " [    0     0     0     0   809     0     0]\n",
      " [    0     0     0     0     0     4     0]\n",
      " [    0     0     0     0     0     0     2]]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
      "              nthread=None, objective='multi:softprob', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=None, subsample=1, verbosity=1)Accuracy: 1.00 (+/- 0.00)\n",
      "Num Features: 3\n",
      "Selected Features: [ True False False False False False  True False  True]\n",
      "Feature Ranking: [1 4 6 7 2 5 1 3 1]\n"
     ]
    }
   ],
   "source": [
    "model1(xgb)\n",
    "crossval(xgb)\n",
    "rfe1(xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(priors=None, var_smoothing=1e-09)Accuracy: 82.6551724137931\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.95      0.88      0.92     11478\n",
      "           2       0.01      0.92      0.02        13\n",
      "           3       0.11      0.59      0.19        39\n",
      "           4       0.89      0.54      0.67      2155\n",
      "           5       0.99      0.82      0.90       809\n",
      "           6       0.40      1.00      0.57         4\n",
      "           7       0.00      1.00      0.01         2\n",
      "\n",
      "    accuracy                           0.83     14500\n",
      "   macro avg       0.48      0.82      0.47     14500\n",
      "weighted avg       0.94      0.83      0.88     14500\n",
      "\n",
      "[[10116   463   185   143     4     5   562]\n",
      " [    1    12     0     0     0     0     0]\n",
      " [    7     1    23     0     1     0     7]\n",
      " [  502   491     0  1162     0     0     0]\n",
      " [    0   142     0     0   666     1     0]\n",
      " [    0     0     0     0     0     4     0]\n",
      " [    0     0     0     0     0     0     2]]\n",
      "GaussianNB(priors=None, var_smoothing=1e-09)Accuracy: 0.81 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "model1(gnb)\n",
    "crossval(gnb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
